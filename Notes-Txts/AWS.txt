--------------------------------
--------------------------------
ARN [Amazon Resource Name]
--------------------------------
Format:
arn:aws:<aws-service>:<aws-region>:<aws-account>:[<resourcetype>:]<service-specific-resource>

Format: 	arn:aws:<aws-service>:<aws-region>:<aws-account>:<service-specific-resource>			
e.g
s3 bucket:  arn:aws:s3           :us-east-1   :123456789012 :my_bucket/logs/*
dynamo tb:  arn:aws:dynamodb     :us-east-1   :123456789012 :table/my_tablle_1
iam user:   arn:aws:iam          :us-east-1   :123456789012 :user/sample_user_1

--------------------------------
--------------------------------
Region >
		AZ >
			Edge Locations 
			[i.e using CloudFront (~AWS's CDN - Content Delivery Networks) ]
			[Reduce Cost/Latency; Caching at multiple layers]
		
Global:
	CloudFront
	Route53
	IAM

Regional Level:
AZ level:

Managed Service:
	Scaling, Falut Tolerance, Avialibilty  By AWS
	i.e 
		 Dynamo,
		 RDS [Via some commands/configs]

Un-Managed Service (do it by yourself):
	Scaling, Falut Tolerance, Avialibilty  By Yourself
	i.e
		ec2
	
ServerLess:
	Lambda	
	
	
--------------------------------
--------------------------------
Cloud Best Practices:
	Auto-Scale
	Automate (Cloud Formation)
	Disposable Resources (shutdown/release/delete when not in use)
	Loosely coupled Components
	Design services; not servers
	Choose right DB
	Design to handle failure of any (aws)services you use [Avoid single point of Failure]
	Optimize for cost
	use caching
	secure your Infra on each layer


Acid  <-> Base [ EventualConsistency]

--------------------------------
--------------------------------
Notes:
- Resources arenâ€™t replicated across regions unless organizations choose to do so.
- Security:
	- AWS helps by sharing the security responsibilities with the organization. 
	- AWS manages the underlying infrastructure, and the organization can secure anything it deploys on AWS. 





--------------------------------
--------------------------------
DynamoDB:
--------------------------------



--------------------------------
--------------------------------
Lamba:
--------------------------------
- AWS Lambda runs your back-end code 
	on its own AWS compute fleet of Amazon EC2 instances 
	across multiple Availability Zones in a region



--------------------------
AWS EMR: Elastic MapReduce
AWS Glue: (Metadata store for spark-sql)

	a cluster to run spark-jobs

Using Amazon EMR version 5.8.0 or later, you can
	configure Spark SQL to use the AWS Glue Data Catalog as its metastore

We recommend this configuration when you require
	a persistent metastore or
	a metastore shared by different clusters, services, applications, or AWS accounts.

AWS Glue crawlers can automatically infer schema from source data in Amazon S3 and store the associated metadata in the Data Catalog.

a monthly rate for storing and accessing the metadata in the Data Catalog,
an hourly rate billed per minute for AWS Glue ETL jobs and crawler runtime, and
an hourly rate billed per minute for each provisioned development endpoint.

The Data Catalog allows you to store up to a million objects at no charge.
If you store more than a million objects, you are charged USD$1 for each 100,000 objects over a million.
An object in the Data Catalog is a table, partition, or database.

Create Hive Table
	without specifying LOCATION,
	Then, hive.metastore.warehouse.dir will be used.
To create a Hive table using AWS Glue:
	either of above must be set to Amazon-S3


--------------------------
Elastic Cache:

	ElastiCache for Redis
	ElastiCache for Memcached
